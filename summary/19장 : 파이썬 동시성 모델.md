> 동시성은 한 번에 여러 일을 처리하는 것이다. 병렬성은 한 번에 여러 일을 하는 것이다. 똑같지는 않지만 서로 관련은 있다. 동시성은 구조의 문제이고, 병렬성은 실행의 문제이다. 동시성은 병렬화할 수 있는 문제를 해결하는 데 필요한 구조를 제공한다.
>

### 개요

스레드나 프로세스는 쉽게 시작할 수 있지만, 그것들을 어떻게 추적해야 할까?

함수를 호출할 때, 호출한 코드는 함수가 반환할 때까지 멈춤. 예외는 try/except로 잡을 수 있음.

그러나 스레드/프로스세는 이런 친숙한 방법을 사용할 수 없고, 결과나 에러를 가져오려면 메시지 큐 등의 통신 채널이 필요함. 또한 스레드/프로세스의 시작 비용은 비쌈. 스레드를 한 번만 쓰고 버리는 대신, 계속 돌아가면서 작업을 기다리는 작업자(worker)로 만들면 처음에 드는 생성 비용을 여러 작업에 걸쳐 충분히 상쇄할 수 있음. 하지만 따라오는 질문들..

- 통신이 복잡해 지지 않나?
- worker가 더 이상 필요 없으면 어떻게 종료해야하지?
- 처리 중이던 데이터와 열린 파일 같은 해제되지 않은 리소스를 놔둔 채 중단하지 않고 어떻게 깔끔하게 작업을 종료할 수 있지?

일반 적인 답은 메시지와 큐

코루틴은 비용이 적게 들고 await을 통해 값을 가져오고 에러 처리도 쉬움. 하지만 비동기 프렝미워크에 의해 시작되어 감시가 어려움

### 용어 정리

`동시성`

대기 중인 여러 태스크를 한 번에 하나씩 (가능 하다면 병렬로)진행해 모든 태스크가 성공하거나 실패할 때까지 처리하는 능력. 멀티태스킹

단일 코어에서도 가능

`병렬성`

여러 계산을 동시에 실행하는 능력. 다중 코어, 다중 CPU, GPU 혹은 클러스터로 묶인 다중 컴퓨터가 필요함

`프로세스`

격리된 메모리 공간을 가진 컴퓨터 프로그램 인스턴스. 각 프로세스간 통신을 위해 파이프, 소켓, 메모리맵 파일을 이용하고 원시 바이트로 직렬화가 필요함.

`스레드`

프로세스 안에 있는 하나의 실행 유닛. 프로세스는 os API를 호출해 동시에 실행되는 스레드를 만들 수 있음. 동일 프로세스 안에 있는 스레드들은 동일한 메모리 공간을 공유

`코루틴`

멈췄다가 나중에 다시 실행을 재개할 수 있는 함수. 파이썬 코루틴은 일반적으로 이벤트 루프의 관리하에 하나의 스레드 안에서 작동함. asyncio, Curio, Trio 등 비동기 프로그래밍 프레임워크는 논블로킹 기반 I/O를 지원함. 코루틴은 yield나 await 키워드로 제어권을 양보해 다른 코루틴이 실행되기헤는 협업형 멀티태스킹을 지원함. 하지만 하나의 코루틴에서 블로킹 이벤트는 전체 이벤트 루프의 블로킹이 됨. 스레드/프로세스의 선점형을 지원하지 않기 때문

- 프로세스, 자식 프로세스, 스레드

  ✅ **요약**

  | **항목** | **B 프로세스** | **A의 자식 프로세스** | **A의 스레드** |
      | --- | --- | --- | --- |
  | **누가 만든 거?** | 운영체제 or 다른 앱 | A가 fork() 또는 spawn() 등으로 생성 | A 내부에서 생성 (pthread, threading) |
  | **메모리 공유?** | ❌ 완전 별개 | ❌ (fork 후 독립적 메모리) | ✅ 메모리 공간 공유 |
  | **PID** | 완전 다른 PID | 고유 PID, PPID는 A | 같은 PID (TID는 다름) |
  | **주소 공간** | 완전히 독립적 | 처음에는 복사, 이후 독립 | 완전히 공유됨 |
  | **A가 죽으면?** | 영향 없음 | 부모 없어도 살아있을 수 있음 | A가 죽으면 같이 종료됨 |
  | **IPC 필요?** | ✅ 필요 | ✅ 필요 | ❌ 직접 변수로 공유 가능 |
  | **장점** | 완전 격리, 안전함 | 독립성 + 제어 가능 | 빠르고 가벼움 |
  | **단점** | 느림, 통신 복잡 | 생성 비용 큼 | 충돌 위험 (동기화 필요) |
    
  ---

  💡 **참고: 자식 프로세스는 왜 ‘제어 가능’한가?**

  A가 직접 만든 자식 프로세스는 OS에 의해 **부모-자식 관계로 연결**되기 때문에 A가 다음과 같은 **제어**를 할 수 있음:

  •	wait() / waitpid() 로 **종료 기다리기**

  •	kill(pid) 로 **프로세스 종료시키기**

  •	**종료 코드 확인**도 가능

  즉, 자식 프로세스는 A가 만든 **“관리 대상”**인 반면, B 프로세스는 관계 없는 **“타인 집 프로세스”**라 제어 불가!

-

`큐`

FIFO 구조체. 애플리케이션 데이터, 에러 코드, 종료 신호 등 실행 유닛들간의 교환을 도와줌. 파이썬 표준 라이브러리에 있는 queue 패키지는 스레드를 지원하는 큐 클래스를 제공하지만, multiprocessing과 asyncio 패키지는 자체 큐 클래스를 구현함. LifoQueue, PriorityQueue도 있음.

`lock`

실행 유닛이 작업을 동기화하고 데이터 훼손을 방지하는 데 사용할 수 있는 객체

`race`

제한된 자원에 대한 다툼. 여러 개의 실행 유닛이 공유 자원에 접근하려고 할 때 자원 경쟁이 발생함.

### 프로세스, 스레드 그리고 GIL

위 개념을 파이썬에 적용하면 10가지로 요약 가능

1. 각각 파이선 인터프리터 인스턴스는 하나의 프로세스임. multiprocessing이나 concurrent.futures 라이브러리로 파이썬 프로세스를 더 만들 수 있음. subprocess 라이브러리는 어떤 언어로 작성된 외부 프로그램도 하나의 프로세스로 실행 가능
    - multiprocessing test

        ```java
        from multiprocessing import Process
        import time
        import os
        
        def child_process():
            print(f"[자식] PID: {os.getpid()}, PPID: {os.getppid()}")
            print("[자식] 100초 동안 sleep 시작")
            time.sleep(100)
            print("[자식] sleep 종료")
        
        if __name__ == '__main__':
            print(f"[부모] PID: {os.getpid()}")
            
            p = Process(target=child_process)
            p.start()
        
            print(f"[부모] 자식 프로세스 PID: {p.pid}")
            print("[부모] 100초 동안 sleep 시작")
            time.sleep(100)
            print("[부모] sleep 종료")
        ```

        ```java
          **501 76230 10593   0  1:31PM ttys001    0:00.05 python pro.py
          501 76231 76230   0  1:31PM ttys001    0:00.03 /Users/leo/anaconda3/bin/python -c from multiprocessing.resource_tracker import main;main(3)
          501 76232 76230   0  1:31PM ttys001    0:00.03 /Users/leo/anaconda3/bin/python -c from multiprocessing.spawn import spawn_main; spawn_main(tracker_fd=4, pipe_handle=6) --multiprocessing-fork**
        ```

2. 파이썬 인터프리터는 GC를 실행하는데 하나의 스레드를 사용함. threading이나 concurrent.futures 라이브러리로 멀티 스레딩 가능
3. 객체 참조 수와 인터프리터 내부 상태에 대한 접근은 GIL이 제어함.
4. 특정 스레드가 GIL을 무한히 잡는 것을 방지하고자, 파이썬의 바이트코드 인터프리터는 기본적으로 현재 파이썬 스레드를 5ms마다 중단하고 GIL을 해제함. 해제 당한 스레드가 다시 가져갈 수도 있고, 다른 스레드가 기다리고 있으면 OS 스케줄러는 그 중 하나를 골라 계속 진행함
   [이 간격을 알고 싶거나](https://docs.python.org/3/library/sys.html#sys.getswitchinterval)   [설정 하고 싶으면](https://docs.python.org/3/library/sys.html#sys.setswitchinterval)
5. 파이썬 코드를 작성할 때 GIL 제어는 불가능. 그러나 C언어 (혹은 파이썬/C API를 호출할 수 있는 언어)로 작성된 내장 함수나 확장 모듈에서는 시간이 오래 걸리는 태스크를 실행할 때 GIL을 해제할 수 있다.
6. 시스템을 호출하는 모둔 파이썬 표준 라이브러리 함수는 GIL을 해제함. 디스크I/O, 네트워크 I/O, zlib, 넘파이 등
7. 파이썬/C API 수준에 통합된 확장 모듈들도 GIL의 영향을 받지 않는 비파이썬 스레드 생성 가능. GIL 영향을 받지 않는 스레드는 파이썬 객체를 변경할 수는 없지만 [버퍼 프로토콜](https://peps.python.org/pep-3118/)을 지원하는 객체의 메모리 영역을 읽거나 쓸 수 있음
8. 파이썬 스레드로 구현한 네트워크 프로그램에서는 GIL의 영향이 상대적으로 적음. I/O 작업은 GIL을 해제하고 오래걸리기 때문
9. GIL을 얻기 위한 경쟁을 CPU 집약적인 스레드 속소 떨어트림. 단일 스레드가 나음
10. 다중 코어 시스템에서 CPU 위주의 파이썬 코드를 실행하려면 멀티 프로세싱을 사용해야함

GIL은 파이썬 언어 정의에 속하지 않음. CPython이 구현한 것일 뿐 Jython, IronPython 구현에는 GIL이 없음.

> 코루틴은 비동기 프레임워크가 제공하는 관리자 이벤트 루프와 동일한 파이썬 스레드를 공유하므로 GIL의 영향을 받지 않음. 여러 스레드를 사용할 수 있지만, 스레드 하나가 이벤트 루프와 모든 코루틴을 실행하고 나머지 스레드는 특정 작업만 수행하는 편이 좋은 프로개밍 방식임
>

### 스피너 - 프로세스, 스레드, asyncio

`스레드로 구현하기`

```python
import itertools
import time
from threading import Thread, Event

# 스피너를 출력하는 함수 (백그라운드에서 돌아감)
def spin(msg: str, done: Event) -> None:
    for char in itertools.cycle(r'\|/-'):  # 계속 반복되는 캐릭터
        status = f'\r{char} {msg}'         # 현재 상태 문자열
        print(status, end='', flush=True) # 같은 줄에 계속 출력
        if done.wait(.1):                 # 0.1초 기다리면서 'done' 이벤트 발생했는지 확인
            break                         # 이벤트가 발생하면 스레드 종료
    blanks = ' ' * len(status)            # 지우기용 공백
    print(f'\r{blanks}\r', end='')        # 콘솔 깔끔하게 정리

# 오래 걸리는 작업 (3초 동안 sleep)
def slow() -> int:
    time.sleep(3)
    return 42
    

# 전체 로직을 관리하는 함수
def supervisor() -> int:
    done = Event()  # '이벤트 발생 여부'를 공유하는 객체 생성
    spinner = Thread(target=spin, args=('thinking!', done))  # 스피너 스레드 생성
    print(f'spinner object: {spinner}')  # 스레드 객체 출력 (디버깅용)
    spinner.start()  # 스레드 시작 (스피너 애니메이션 시작)
    result = slow()  # 메인 작업 실행 (이때 스피너가 돌아감)
    done.set()       # 작업 끝났으니 '이벤트 발생' 신호 보냄 → 스피너에게 알려줌
    spinner.join()   # 스피너 스레드가 끝날 때까지 기다림
    return result

# 프로그램 시작 지점
def main() -> None:
    result = supervisor()  # 전체 흐름 실행
    print(f'Answer: {result}')

if __name__ == '__main__':
    main()
```

threading Event

•	스레드 간 신호를 주고받기 위한 동기화 도구
•	기본 상태는 “꺼짐(False)”
•	.set()을 호출하면 상태가 “켜짐(True)“으로 바뀜
•	다른 스레드는 .wait(timeout)을 호출해서 “이벤트가 켜졌는지” 기다릴 수 있음

`프로세스로 구현하기`

```python
import itertools
import time
from multiprocessing import Process, Event  # 프로세스 생성, 이벤트 객체 임포트
from multiprocessing import synchronize     # 타입 힌트를 위한 모듈 (선택적)

# 스피너 애니메이션을 출력하는 함수
# 'done'은 Event 객체로, 부모 프로세스와 신호를 주고받음
def spin(msg: str, done: synchronize.Event) -> None:
    for char in itertools.cycle(r'\|/-'):       # 무한 루프로 스피너 돌아감
        status = f'\r{char} {msg}'
        print(status, end='', flush=True)       # 같은 줄에 계속 덮어쓰기
        if done.wait(.1):                       # 0.1초마다 이벤트 발생했는지 확인
            break                               # done.set()이 호출되면 종료
    blanks = ' ' * len(status)                  # 깔끔하게 화면 지우기
    print(f'\r{blanks}\r', end='')

# 오래 걸리는 작업을 시뮬레이션 (3초 대기)
def slow() -> int:
    time.sleep(3)
    return 42

# 전체 로직을 조율하는 함수
def supervisor() -> int:
    done = Event()                              # 부모와 자식 간의 이벤트 객체 생성
    spinner = Process(target=spin,              # 자식 프로세스로 spin 함수 실행
                      args=('thinking!', done)) # 메시지와 이벤트 전달
    print(f'spinner object: {spinner}')         # 자식 프로세스 객체 정보 출력
    spinner.start()                             # 자식 프로세스 시작 (스피너 실행됨)
    result = slow()                             # 메인 작업 실행 (이때 자식은 스피너 중)
    done.set()                                  # 작업 완료 → 자식에게 "멈춰!" 신호 보냄
    spinner.join()                              # 자식 프로세스가 끝날 때까지 대기
    return result

# 메인 함수: 전체 프로그램 실행
def main() -> None:
    result = supervisor()
    print(f'Answer: {result}')

# 실행 지점
if __name__ == '__main__':
    main()
```

multiprocessing API들은 threading API와 비슷하지만 구현은 아주 다름. 프로세스들은 OS에 의해 독립된 공간을 가지기 때문에 프로세스 간에 통신할 방법을 만들어야함. 직렬화/역직렬화도 필요하고 프로세스를 넘나드는 Event도 필요. 해당 Event는 C 언어로 구현된 저수준 OS 세마포어로 구현됨.

> 3.8부터 multiprocessing.shared_memory 패키지가 포함되었지만 [built-in data type](https://docs.python.org/3/library/multiprocessing.shared_memory.html#multiprocessing.shared_memory.ShareableList)만 지원함
>
- [shared_memory 주요 구성 요소](https://docs.python.org/3/library/multiprocessing.shared_memory.html)

  **1. SharedMemory 클래스**

  •	**목적**: 메모리 블록 생성 및 공유

  •	**주요 메서드**:

  •	close(): 해당 인스턴스에서 메모리 접근 종료

  •	unlink(): 공유 메모리 삭제 (한 번만 호출해야 함)

  •	**속성**:

  •	buf: 메모리 내용에 접근하는 memoryview

  •	name: 메모리 블록 이름

  •	size: 메모리 크기

  **2. SharedMemoryManager 클래스**

  •	**BaseManager**의 서브클래스

  •	**start()/shutdown()**으로 별도 프로세스에서 공유 메모리 관리

  •	SharedMemory() 및 ShareableList() 생성 지원

  **3. ShareableList 클래스**

  •	공유 메모리 기반 **고정 길이 리스트**

  •	지원 타입:

  •	int, float, bool, str (UTF-8, <10MB), bytes, None

  •	제한:

  •	append(), insert() 등 리스트 길이 변경 불가

  •	slicing으로 새 리스트 만들 수 없음

  •	문자열/바이트 끝에 \x00이 붙으면 자동으로 잘릴 수 있음 (버그)


`코루틴으로 구현하기`

```python

import asyncio
import itertools

# 스피너 애니메이션을 출력하는 비동기 함수
# 'thinking!' 메시지를 보여주며, asyncio.CancelledError가 발생할 때까지 루프
async def spin(msg: str) -> None:
    for char in itertools.cycle(r'\|/-'):           # 무한 루프: 스피너 애니메이션
        status = f'\r{char} {msg}'                  # 메시지 앞에 스피너 기호 붙이기
        print(status, flush=True, end='')           # 줄 바꿈 없이 출력 (덮어쓰기)
        try:
            await asyncio.sleep(.1)                 # 0.1초마다 쉼 (다른 작업 양보)
        except asyncio.CancelledError:              # 취소 신호 받으면 루프 종료
            break
    blanks = ' ' * len(status)                      # 화면을 깔끔하게 지우기 위한 공백
    print(f'\r{blanks}\r', end='')                  # 스피너 지우고 줄 초기화

# 오래 걸리는 작업을 비동기 함수로 구현 (3초 대기)
async def slow() -> int:
    await asyncio.sleep(3)
    return 42

# 메인 함수: 프로그램 진입점
def main() -> None:
    result = asyncio.run(supervisor())              # 비동기 supervisor() 실행
    print(f'Answer: {result}')                      # 결과 출력

# 전체 비동기 작업을 조율하는 함수
async def supervisor() -> int:
    spinner = asyncio.create_task(spin('thinking!'))  # 스피너 태스크 비동기로 실행
    print(f'spinner object: {spinner}')               # 태스크 객체 정보 출력
    result = await slow()                             # 메인 작업 실행 (이때 스피너도 동작 중)
    spinner.cancel()                                  # 작업 완료 → 스피너 태스크 취소
    return result

# 실행 지점
if __name__ == '__main__':
    main()
```

스레드와 프로세스에 CPU 시간을 할당하는 것은 OS 스케줄러의 몫. 이와 반대로 코루틴은 애플리케이션 수준 이벤트 루프가 코루틴 큐를 관리함. 이벤트 루프는 코루틴을 하나씩 구동하고, I/O 이벤트 감시하고 제어권 전달 등. 이는 모두 하나의 스레드에서 실행됨.

코루틴을 실행하는 세 가지 주요 방법

`asynci.run(coro())`

코루틴 객체를 실행하기 위해 일반 함수에서 호출

`asyncio.create_tast(coro())`

또 다른 코투린을 스케줄링하기 위해 코루틴 안에서 호출. 현재 코루틴을 중단시키지 않고 Task 인스턴스를 바로 반환

`await coro()`

코루틴 안에서 호출되어 coro()가 반환한 코루틴 객체로 제어권을 넘겨줌. coro()가 반환될 때까지 현재 코루틴을 정지.

> coro() 형태로 호출하면 코루틴 객체가 반환되지만, coro() 함수 본체를 실행시키지 않음. 코루틴 본체를 실행하는 것은 이벤트 루프의 일.
>

프로그램 전체를 멈추고 싶은게 아니라면 asyncio 코루틴 안에서 절대로 time.sleep(…)을 사용하면 안됨. 이벤트 루프 스레드도 sleep이 되어서 전체 Task 모두 sleep

- [greenlet](https://greenlet.readthedocs.io/en/latest/), [gevent](https://www.gevent.org/), asyncio


    | 특성 | greenlet | gevent | asyncio |
    | --- | --- | --- | --- |
    | **기본 개념** | 경량화된 코루틴 | greenlet 기반 네트워킹 라이브러리 | 표준 라이브러리 비동기 프레임워크 |
    | **Python 버전** | 모든 버전 지원 | 모든 버전 지원 | Python 3.4+ |
    | **스케줄링 방식** | 협력적(명시적 전환 필요) | 협력적(이벤트 기반 자동 전환) | 협력적(async/await 기반) |
    | **구문 지원** | 일반 Python 코드 | 일반 Python 코드 | async/await 키워드 |
    | **이벤트 루프** | 없음(직접 구현 필요) | libev 또는 libuv | 내장 이벤트 루프 |
    | **주요 특징** | 가벼움, C 함수 스택 지원 | Monkey patching, 네트워크 최적화 | 언어 수준 지원, 표준화 |
    | **주요 사용 사례** | 저수준 제어가 필요한 경우 | 네트워크 IO 중심 애플리케이션 | 모던 비동기 애플리케이션 |
    | **제어 흐름** | 프로그래머가 완전히 제어 | 이벤트 루프에 의해 관리 | 이벤트 루프에 의해 관리 |
    | **설치** | 별도 설치 필요 | 별도 설치 필요 | Python 3.4+ 기본 내장 |
    | **추가 기능** | 최소 기능 | 소켓, DNS, HTTP 서버, 스레드 풀 | Task, Future, Queue 등 |
    | **통합성** | 다른 라이브러리와 쉽게 통합 | Monkey patching으로 기존 코드 변환 | 생태계 확장 중 |
    | **SQLAlchemy 지원** | 내부적으로 사용됨 | 직접 지원하지 않음 | 1.4+ 버전에서 지원 |
    
    ## 선택 기준
    
    - **greenlet**: 직접적인 제어 흐름 관리가 필요하거나 저수준 코루틴이 필요할 때
    - **gevent**: 기존 동기식 코드를 최소한의 변경으로 비동기화하거나 네트워크 성능이 중요할 때
    - **asyncio**: 새 프로젝트, 최신 Python 기능 활용, 표준 라이브러리만으로 개발할 때
    
    ---
    
    **📚 기술적 배경**
    
    **greenlet의 스택 전환 방식:**
    
    •	greenlet은 **스택풀링(stackful coroutine)** 방식의 코루틴 구현체다.
    
    •	즉, 실행 중인 함수 호출 스택 전체를 **사용자 공간(user space)**에서 저장하고 전환(switch)할 수 있다.
    
    •	이 과정은 Python 스택뿐만 아니라 **C 스택 프레임**도 포함된다.
    
    •	이 기능은 setjmp/longjmp 또는 이에 준하는 **비표준 스택 전환 매커니즘**을 통해 구현된다 (플랫폼 의존적 C 수준 API 활용).
    
    **asyncio의 한계:**
    
    •	Python 3의 asyncio는 **stackless coroutine**, 즉 **스택 없는 코루틴**으로 설계되어 있다.
    
    •	모든 컨텍스트 전환은 await 가능한 지점에서만 발생하며, 이 지점은 반드시 **Python 해석기 수준에서 명시적으로 정의**되어야 한다.
    
    •	따라서 asyncio는 **C 확장 함수나 외부 바이너리 라이브러리** 호출 중에는 제어권을 획득할 수 없다.
    
    •	예: time.sleep() 또는 NumPy의 C 함수 호출 시에는 이벤트 루프가 블로킹된다.
    
    ---
    
    **🧩 gevent와 C 스택 전환**
    
    •	gevent는 greenlet을 이용해 **비동기 I/O를 동기식 코드처럼 작성**할 수 있는 프레임워크이다.
    
    •	내부적으로는 I/O 이벤트 루프(libev 또는 libuv 등)와 greenlet 간의 컨텍스트 전환을 통해 스케줄링된다.
    
    •	이때 중요한 점은, gevent의 monkey patching을 통해 표준 라이브러리의 socket, time.sleep 등의 함수 호출 중에도 **스레드나 이벤트 루프 전환 없이도** 다른 greenlet으로 안전하게 스위치할 수 있다는 점이다.
    
    •	이는 전적으로 **greenlet의 스택 전환 능력(C 스택 포함)** 덕분이다.
    
    ---
    
    **⚠️ Caveats 및 실무적 고려 사항**
    
    •	C 함수가 실행 중일 때 전환이 **가능하다고 해도 안전한 것은 아님**.
    
    특히 C 함수가 외부 자원이나 내부 상태를 갖고 있는 경우 전환 후 복귀 시 예기치 않은 동작이 발생할 수 있음.
    
    •	greenlet이나 gevent 기반 설계는 **디버깅이 어렵고**, Python의 표준 흐름(asyncio, threading)과는 다르기 때문에 장기적인 유지보수 관점에서 주의가 필요함.
    
    ---
    
    **✅ 정리**
    
    | **항목** | asyncio | greenlet **/** gevent |
    | --- | --- | --- |
    | 코루틴 방식 | Stackless | Stackful |
    | C 스택 중 전환 가능 | ❌ 불가능 | ✅ 가능 |
    | 전환 지점 제약 | await 또는 명시적인 코루틴 문법 필요 | 언제든 switch() 호출로 전환 가능 |
    | 전환 구현 수준 | Python 레벨 | C 레벨 (저수준 스택 조작 포함) |
    | 대표 라이브러리 | asyncio, trio | greenlet, gevent, eventlet |
    
    ---


### GIL의 실제 영향

spinner의 slow 코드를 is_prime로 변경하면 멀티 스레딩, 멀티 프로세스, asyncio에서 어떻게 될까?

```python
'''
이거 3.13 GIL 한 번 비교해보자.
'''
def is_prime(n):
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False

    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True
    
def slow() -> int:
    is_prime(5_000_111_000_222_021)
    return 42

async def is_prime_async(n):
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    
    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True

async def slow_async() -> int:
    await is_prime_async(5_000_111_000_222_021)
    return 42
    
```

멀티프로세스 : 자식 프로세스가 스피너를 제어하므로 부모 프로세스가 숫자가 소수인지 확인하는 동안 스피너가 계속 돌아감. (우리는 선점형 멀티태스킹 OS를 사용하니..)

멀티스레드 : 계속 스피너 돌아감. 기본값을 변경하지 않았다면 5ms마다 실행중인 스레드를 중단시키고, 대기중인 스레드에게 GIL을 제공하기 때문.

asyncio : time.sleep()과 똑같은 일이 생김. 제어 흐름이 중간에 안 넘어오기 때문.

- [asyncio.sleep(0)을 이용한 파워 냅](https://github.com/python/asyncio/issues/284)
    1. 문제 제기: Python 3.5부터 `async def` 코루틴 내에서 `yield`를 사용할 수 없게 되었으므로, 이벤트 루프에 제어권을 넘기는 적절한 방법이 필요했습니다.
    2. 해결 방안 논의:
        - 초기에는 `AsyncNone` 클래스와 같은 사용자 정의 객체 생성 방법이 제안됨
        - Guido van Rossum과 다른 개발자들은 `asyncio.sleep(0)`을 사용하는 것이 가장 간단한 해결책이라고 제안
    3. 최종 결정:
        - PR #285에서 `asyncio.sleep(0)`의 성능을 최적화하여 이 용도로 사용하기 적합하게 만듦
        - 공식적으로 `asyncio.sleep(0)`이 이벤트 루프에 제어권을 넘기는(yield) 표준 방법으로 채택됨
    4. 추가 논의:
        - 문서화 필요성: 이 패턴이 문서에 명확히 기술되어야 한다는 의견
        - 사용 사례: 주로 장시간 실행되는 연산 중간에 다른 태스크가 실행될 기회를 주고 싶을 때 유용

  결론적으로, Python 비동기 프로그래밍에서 이벤트 루프에 제어권을 넘기려면 `await asyncio.sleep(0)`을 사용하는 것이 표준 방법으로 정해졌습니다. 이는 UI 스피너와 같은 요소가 업데이트될 수 있도록 하는 데 효과적입니다.


### 직접 만든 프로세스 풀

CPU 위주 함수 여러 개를 호출하는 방법

> 이 절은 여러 개의 CPU 위주 프로세스를 사용해 태스크를 분산하고 결과를 취합하는 데 큐를 사용하는 일반적인 패턴을 보여줌
>

```python
## procs.py

import sys
from time import perf_counter
from typing import NamedTuple
from multiprocessing import Process, SimpleQueue, cpu_count  # <1>
from multiprocessing import queues  # <2> 프로세스 간 공유를 전제로 만든 큐

from primes import is_prime, NUMBERS

class PrimeResult(NamedTuple):  # <3>
    n: int
    prime: bool
    elapsed: float

JobQueue = queues.SimpleQueue[int]  # <4>
ResultQueue = queues.SimpleQueue[PrimeResult]  # <5>

def check(n: int) -> PrimeResult:  # <6>
    t0 = perf_counter()
    res = is_prime(n)
    return PrimeResult(n, res, perf_counter() - t0)

def worker(jobs: JobQueue, results: ResultQueue) -> None:  # <7>
    while n := jobs.get():  # <8>
        results.put(check(n))  # <9>
    results.put(PrimeResult(0, False, 0.0))  # <10>

def start_jobs(
    procs: int, jobs: JobQueue, results: ResultQueue  # <11>
) -> None:
    for n in NUMBERS:
        jobs.put(n)  # <12>
    for _ in range(procs):
        proc = Process(target=worker, args=(jobs, results))  # <13>
        proc.start()  # <14>
        jobs.put(0)  # <15>
# end::PRIMES_PROC_TOP[]

# tag::PRIMES_PROC_MAIN[]
def main() -> None:
    if len(sys.argv) < 2:  # <1>
        procs = cpu_count()
    else:
        procs = int(sys.argv[1])

    print(f'Checking {len(NUMBERS)} numbers with {procs} processes:')
    t0 = perf_counter()
    jobs: JobQueue = SimpleQueue()  # <2>
    results: ResultQueue = SimpleQueue()
    start_jobs(procs, jobs, results)  # <3>
    checked = report(procs, results)  # <4>
    elapsed = perf_counter() - t0
    print(f'{checked} checks in {elapsed:.2f}s')  # <5>

def report(procs: int, results: ResultQueue) -> int: # <6>
    checked = 0
    procs_done = 0
    while procs_done < procs:  # <7>
        n, prime, elapsed = results.get()  # <8> (https://docs.python.org/3/library/queue.html#queue.SimpleQueue.get)
        if n == 0:  # <9>
            procs_done += 1
        else:
            checked += 1  # <10>
            label = 'P' if prime else ' '
            print(f'{n:16}  {label} {elapsed:9.6f}s')
    return checked

if __name__ == '__main__':
    main()
```

> [SimpleQueue.get()](https://docs.python.org/3/library/queue.html#queue.SimpleQueue.get) 큐에 항목이 put 될 때까지 block이 default. non-block, time-out 설정 가능
>

[저자가 이전에 작성한 코드는 race condition 위험이 있음](https://github.com/fluentpython/example-code-2e/commit/2c1230579db99738a5e5e6802063bda585f6476d#diff-29174501f8cbfc5c5363289143a3765c0cc9c12e11f71b7d53f8b2cc1760f13aL30-R72)

근데… 그냥 저 코드에서는 큰 문제 없지 않나? 일반적인 시나리오는 좀 문제가 있겠지만.

- 루프, 센티넬, 포이즌 필

  `worker()` 는 큐에서 항목을 가져와 실제 작업을 수행하는 함수를 이용해 해당 항목을 처리하면서 무한 루프를 돌다가 큐에서 센티넬 값이 나오면 루프를 종료함. 이 종료시키는 센티넬값을 흔히 ‘포이즌 필’ 이라고 부름.

  None이 실제 유요한 값으로 사용 되는 경우가 있어서 None을 센티넬로 사용 못 하는 경우도 있음.

  object()를 호출하는 방법도 널리 사용되지만, 멀티 프로세싱에서 역/직렬화 중 원래 인스턴스와 정체성이 달라서 동일한 객체가 아니기에 사용 못 함.
  Ellipsis(…) 내장 객체를 사용하기도 함. 역/직렬화에서 동일성이 안 깨짐.

  [파이썬 표준 라이브러리에서 사용하는 센티널 값들](https://mail.python.org/archives/list/python-dev@python.org/message/JBYXQH3NV3YBF7P2HLHB5CD6V3GVTY55/)

  [PEP-661 - 표준 센티널 제안](https://peps.python.org/pep-0661/)


저자는 프로세스를 늘려가며 실험을 해봄. 그런데 프로세스 갯수가 CPU 갯수보다 더 늘어난 상태에서 프로세스를 증가 시켰는데도 실행 시간이 오히려 줄어듦. 예상과 다른데 이유를 모른다고 함.

OS는 마법과도 같다.

multiprocessing 대신 threading을 사용하면 훨씬 느려짐. CPU 경쟁, context switch 때문. 스레드 전환 시마다 CPU는 컨텍스트 스위칭을 위해 레지스터, 스택 포인터, 프로그램 카운터 등을 저장하고 복원해야 함. 이 과정은 비싸기도 하고 CPU Cache hit rate도 떨어트림.

### 멀티코어 세상의 파이썬

- [The Free Launch Is Over](http://www.gotw.ca/publications/concurrency-ddj.htm)
    
  ---

  **✅ 요약해보면:**

  **💻 1. 과거에는 ‘공짜 성능 향상’이 있었다**

  •	CPU 성능이 계속 향상되면서(클럭 속도 증가, 실행 최적화, 캐시 증가 등) **소프트웨어를 수정하지 않아도 자동으로 빨라졌어요.**

  •	“지금 조금 느려도 괜찮아. 내년에 나올 CPU에서는 빨라질 거야.” → 이런 식의 마인드였죠.

  **⚠️ 2. 하지만 더 이상 클럭 속도를 높일 수 없다**

  •	발열, 전력, 누설 전류 등 물리적 한계 때문에 CPU 클럭 속도 증가가 **2003년경부터 멈췄어요.**

  •	인텔은 4GHz CPU도 포기했고, 10GHz는 꿈도 못 꿔요.

  **🔀 3. 그래서 CPU 성능 향상 방향이 바뀌었다**

  •	더 이상 ‘순차 처리 속도’로는 성능을 못 끌어올려서 **‘동시성(Concurrency)’**, 즉 **멀티코어, 하이퍼스레딩** 같은 방식으로 성능을 높이고 있어요.

  •	→ 즉, 이제는 **여러 개의 작업을 동시에 처리해야 CPU를 제대로 활용**할 수 있어요.

  **👩‍💻 4. 그렇다면 소프트웨어는?**

  •	문제는 대부분의 기존 소프트웨어가 **싱글스레드(순차처리)**로 만들어져 있다는 점이에요.

  •	즉, 아무리 CPU가 멀티코어여도, **앱이 1개 코어만 쓰면 성능 향상은 없음**.

  **🧠 5. 앞으로는 동시성 프로그래밍이 필수**

  •	이제부터는 성능을 얻으려면 **멀티스레드/병렬 처리**를 직접 설계해야 해요.

  •	마치 90년대에 객체지향 프로그래밍을 배워야 했던 것처럼, **앞으로는 동시성 프로그래밍을 이해하고 잘 써야 함**.
    
  ---

  **🤯 그런데 왜 다 어렵다고 할까?**

  •	동시성은 어렵고, 버그가 생기기 쉽고, 테스트도 어려움.

  •	특히 멀티코어에서만 드러나는 버그도 있어서 **개발자 입장에서 큰 부담**.

  •	하지만 이제는 **이걸 안 하면 성능을 못 끌어올리니까 피할 수 없음.**
    
  ---

  **🧾 결론**

  •	✅ 지금 당장 CPU-bound(계산이 많은) 작업이 있거나 앞으로 그런 앱을 만들 거면, 동시성 프로그래밍을 배워야 함.

  •	✅ 라이브러리, 언어, 프레임워크도 점점 동시성 중심으로 발전할 것.

  •	✅ 앞으로는 효율적인 코드가 점점 더 중요해질 것.
    
  ---


Cpython을 만들 당시 GIL을 당연한 것이었다. 또한 GIL은 파이썬/C API를 통해 간단한 확장 모듈을 작성하는 일도 더 쉽게 하도록 해주었다.

`시스템 관리`

서버, 라우터, 로드 밸런서, NAS 등 구성된 대형 네트워크 관리에 많이 사용됨. 원격 장비에서 실행할 명령을 호출해 형상 관리 작업을 자동화 하므로 CPU 연산이 많이 필요한 작업은 거의 없음.

표준 라이브러리 외에도 [Ansible](https://www.redhat.com/en/ansible-collaborative?intcmp=7015Y000003t7aWQAQ), [Salt](https://saltproject.io/), [Fabric](https://www.fabfile.org/) 등이 있음.

`데이터 과학`

C/C++ Extension

[프로젝트 주피터](https://jupyter.org/)

- 네트워크에 연결된 원격 장비에서 분석 코드를 실행하고 문서화하게 해 주는 웹 기반 인터페이스
- 다른 언어로 작성된 계산 커널 지원하고, 분산 애플리케이션을 위한 비동기 메세지 라이브러리 ZeroMQ를 통해 통합함
- [Bokeh 라이브러리](https://docs.bokeh.org/en/latest/index.html) (대화형 시각화 라이브러리)

[텐서 플로](https://www.tensorflow.org/?hl=ko) [파이토치](https://pytorch.org/)

- 딥 러닝 라이브러리
- C++로 작성되었고, 다중 코어, GPU, 클러스터 활용 가능

[대스크](https://www.dask.org/)

- 작업을 지역 프로세스나 클러스터 컴퓨터에 임대해 주는 병렬 컴퓨팅 라이브러리.
- 병렬/분산 컴퓨팅 라이브러리. pandas, NumPy, scikit-learn처럼 생긴 작업을 멀티코어 또는 멀티머신에서 병렬로 실행해주는 도구

`서버 웹/모바일 개발`

> 고성능에 대한 동경/웹 스케일에 대한 동경
대단한 엔지니어링이 필요한 경우는 드물다. 제대로 작동하는 간단한 기술이 있는지 확인하자.
필요 없는 복잡성을 지양하자
>

![image.png](attachment:c2f0e4b3-cf8e-4c84-bc67-10a258f3de11:image.png)

특정 언어에 구애받지 않는 구조.

`WSGI 애플리케이션 서버`

[웹 서버 게이트웨이 인터페이스](https://peps.python.org/pep-3333/) 파이썬 프레임워크나 애플리케이션이 HTTP 서버로부터 요청을 받고 응답을 보내는 표준 API. WSGI 애플리케이션 서버는 애플리케이션에서 실행되는 하나 이상의 프로세스를 관리하며 가용 CPU를 최대로 활용하게 해줌

- [mod_wsgi](https://modwsgi.readthedocs.io/en/master/)
- [uWSGI](https://uwsgi-docs.readthedocs.io/en/latest/)
- [Gunicorn](https://gunicorn.org/)
- [NGINX Unix](https://unit.nginx.org/)

위 녀석들이 여러 개의 파이썬 프로세스를 생성해 장고, 플라스크, 피라미드 등 프레임워크를 이용한 순차 코드로 작성된 웹 애플리케이션을 실행함. 그 덕분에 threading, multiprocessing, asyncio 공부 안 해도 그럭 저럭 개발자로 먹고 살게 해줌.

> WSGI는 동기식 API. 웹소켓, HTTP 롱 폴링을 가장 효율적으로 구현하게 해 주는 async/await을 이용한 코루틴을 지원하지 않음. [ASGI](https://asgi.readthedocs.io/en/latest/index.html)를 사용해 비동기 처리를 하자.
>

`분산 태스크 큐`

서버는 최대한 빨리 응답을 주는 것이 좋다. 메일 발송, PDF 파일 생성은 오래 걸린다. 태스크 큐를 통해 이를 해결하자. 아래는 오픈소스 테스크 큐

- [Celery](https://docs.celeryq.dev/en/stable/getting-started/introduction.html)
- [RQ](https://python-rq.org/)

> 태스크 큐에서는 전통적인 클라이언트/서버라는 용어 대신 생산자/소비자 라는 용어를 사용함
>

### 마지막

3.13, 3.13 —no-gil  procs.py, [threads.py](http://threads.py) 를 비교해 보자.